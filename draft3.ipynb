{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from zipfile import ZipFile\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data location\n",
    "#base_path = \"/Users/nikkibytes/Documents/niblunc/BCP/BCP_DATA\"#\"/Users/nikkibytes/Documents/BCP_DATA\"\n",
    "basepath = \"/Users/gracer/Google Drive/BCP/data\"\n",
    "#text4_files=glob.glob(os.path.join(base_path, \"set*/*/*/*04.txt\"))\n",
    "#text9_files=glob.glob(os.path.join(base_path, \"set*/*/*/*09.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data from the zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = {}\n",
    "for (dirpath, dirnames, filenames) in os.walk(basepath):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.zip'):\n",
    "            #print(filename)\n",
    "            tmppath=os.sep.join([dirpath, filename])\n",
    "            #print(tmppath)\n",
    "            with ZipFile(tmppath, 'r') as zipObj:\n",
    "               # Get a list of all archived file names from the zip\n",
    "               listOfFileNames = zipObj.namelist()\n",
    "               # Iterate over the file names\n",
    "               for fileName in listOfFileNames:\n",
    "                   # Check filename endswith csv\n",
    "                    if fileName.endswith('04.txt'):\n",
    "                                           # Extract a single file from zip\n",
    "                        zipObj.extract(fileName, os.path.join(basepath,'temp_txt'))\n",
    "                    if fileName.endswith('09.txt'):\n",
    "                                           # Extract a single file from zip\n",
    "                        zipObj.extract(fileName, os.path.join(basepath,'temp_txt'))\n",
    "infile = os.path.join(basepath,'temp_txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary of the files we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {\"set_04\": {\"mom\":{}, \"child\": {}}, \"set_09\": {\"mom\": {}, \"child\": {}}}\n",
    "file_dict['set_04'][\"mom\"][\"files\"] = [x for x in glob.glob(os.path.join(infile,'*04.txt')) if \"Mom\" in x]\n",
    "file_dict['set_09'][\"mom\"][\"files\"] = [x for x in glob.glob(os.path.join(infile,'*09.txt')) if \"Mom\" in x]\n",
    "file_dict['set_04'][\"child\"][\"files\"] = [x for x in glob.glob(os.path.join(infile,'*04.txt')) if \"Chil\" in x]\n",
    "file_dict['set_09'][\"child\"][\"files\"] = [x for x in glob.glob(os.path.join(infile,'*09.txt')) if \"Chil\" in x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataframe size:  (360, 226)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project Abbreviation</th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Date of Intake</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Record Type</th>\n",
       "      <th>Participant Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Date of Entry</th>\n",
       "      <th>Day of Intake</th>\n",
       "      <th>...</th>\n",
       "      <th>Data Field 1 Descriptor</th>\n",
       "      <th>Data Field 1 Response</th>\n",
       "      <th>Data Field 2 Descriptor</th>\n",
       "      <th>Data Field 2 Response</th>\n",
       "      <th>Data Field 3 Descriptor</th>\n",
       "      <th>Data Field 3 Response</th>\n",
       "      <th>Data Field 4 Descriptor</th>\n",
       "      <th>Data Field 4 Response</th>\n",
       "      <th>Data Field 5 Descriptor</th>\n",
       "      <th>Data Field 5 Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCPMomMSTR</td>\n",
       "      <td>1995</td>\n",
       "      <td>06/06/2017</td>\n",
       "      <td>Baby ConnectoMe Project, Mom MASTER, Q4 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/14/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Data Field 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCPMomMSTR</td>\n",
       "      <td>11370</td>\n",
       "      <td>05/30/2017</td>\n",
       "      <td>Baby ConnectoMe Project, Mom MASTER, Q4 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Data Field 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCPMomMSTR</td>\n",
       "      <td>11370</td>\n",
       "      <td>08/23/2017</td>\n",
       "      <td>Baby ConnectoMe Project, Mom MASTER, Q4 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Data Field 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCPMomMSTR</td>\n",
       "      <td>17541</td>\n",
       "      <td>05/30/2017</td>\n",
       "      <td>Baby ConnectoMe Project, Mom MASTER, Q4 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/02/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Data Field 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCPMomMSTR</td>\n",
       "      <td>20784</td>\n",
       "      <td>12/13/2016</td>\n",
       "      <td>Baby ConnectoMe Project, Mom MASTER, Q4 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/14/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Data Field 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Field 5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project Abbreviation Participant ID Date of Intake  \\\n",
       "0           BCPMomMSTR           1995     06/06/2017   \n",
       "1           BCPMomMSTR          11370     05/30/2017   \n",
       "2           BCPMomMSTR          11370     08/23/2017   \n",
       "3           BCPMomMSTR          17541     05/30/2017   \n",
       "4           BCPMomMSTR          20784     12/13/2016   \n",
       "\n",
       "                                   Project Name  Record Type  \\\n",
       "0  Baby ConnectoMe Project, Mom MASTER, Q4 2017            1   \n",
       "1  Baby ConnectoMe Project, Mom MASTER, Q4 2017            1   \n",
       "2  Baby ConnectoMe Project, Mom MASTER, Q4 2017            1   \n",
       "3  Baby ConnectoMe Project, Mom MASTER, Q4 2017            1   \n",
       "4  Baby ConnectoMe Project, Mom MASTER, Q4 2017            1   \n",
       "\n",
       "   Participant Name  Gender  Date of Birth Date of Entry  Day of Intake  ...  \\\n",
       "0               NaN       3            NaN    12/14/2017              2  ...   \n",
       "1               NaN       3            NaN    11/21/2017              2  ...   \n",
       "2               NaN       3            NaN    11/21/2017              3  ...   \n",
       "3               NaN       3            NaN    01/02/2018              2  ...   \n",
       "4               NaN       3            NaN    12/14/2017              2  ...   \n",
       "\n",
       "  Data Field 1 Descriptor Data Field 1 Response Data Field 2 Descriptor  \\\n",
       "0            Data Field 1                   NaN            Data Field 2   \n",
       "1            Data Field 1                   NaN            Data Field 2   \n",
       "2            Data Field 1                   NaN            Data Field 2   \n",
       "3            Data Field 1                   NaN            Data Field 2   \n",
       "4            Data Field 1                   NaN            Data Field 2   \n",
       "\n",
       "   Data Field 2 Response  Data Field 3 Descriptor  Data Field 3 Response  \\\n",
       "0                    NaN             Data Field 3                    NaN   \n",
       "1                    NaN             Data Field 3                    NaN   \n",
       "2                    NaN             Data Field 3                    NaN   \n",
       "3                    NaN             Data Field 3                    NaN   \n",
       "4                    NaN             Data Field 3                    NaN   \n",
       "\n",
       "   Data Field 4 Descriptor  Data Field 4 Response  Data Field 5 Descriptor  \\\n",
       "0             Data Field 4                    NaN             Data Field 5   \n",
       "1             Data Field 4                    NaN             Data Field 5   \n",
       "2             Data Field 4                    NaN             Data Field 5   \n",
       "3             Data Field 4                    NaN             Data Field 5   \n",
       "4             Data Field 4                    NaN             Data Field 5   \n",
       "\n",
       "   Data Field 5 Response  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = []            \n",
    "for file in file_dict[\"set_04\"][\"mom\"][\"files\"]:\n",
    "    temp_df =  pd.read_csv(file, sep=\"\\t\", encoding='latin1')\n",
    "    temp_df=temp_df.drop([0])\n",
    "    for val in temp_df[\"Participant ID\"]:\n",
    "        _id = str(val).lstrip(\"0\").split(\"_\")[0]\n",
    "        temp_df.replace(val, _id, inplace=True)\n",
    "    #print(updated_df[\"Participant ID\"])\n",
    "    temp_list.append(temp_df)\n",
    "    #print(temp_df.shape)\n",
    "dfm4_original = pd.concat(temp_list, ignore_index=True)\n",
    "print(\"Final dataframe size: \", dfm4_original.shape)\n",
    "\n",
    "dfm4_original.head()\n",
    "dfm4_orignal = dfm4_original.sort_values(by=\"Participant ID\")\n",
    "dfm4_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataframe size:  (368, 171)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project Abbreviation</th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Date of Intake</th>\n",
       "      <th>FRU0100</th>\n",
       "      <th>FRU0200</th>\n",
       "      <th>FRU0300</th>\n",
       "      <th>FRU0400</th>\n",
       "      <th>FRU0500</th>\n",
       "      <th>FRU0600</th>\n",
       "      <th>FRU0700</th>\n",
       "      <th>...</th>\n",
       "      <th>MSC0300</th>\n",
       "      <th>MSC0400</th>\n",
       "      <th>MSC0500</th>\n",
       "      <th>MSC0600</th>\n",
       "      <th>MSC0700</th>\n",
       "      <th>MSC0800</th>\n",
       "      <th>MSC0900</th>\n",
       "      <th>MSC1000</th>\n",
       "      <th>GRW1300</th>\n",
       "      <th>GRS1300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCPMomAP</td>\n",
       "      <td>11370</td>\n",
       "      <td>11/29/2017</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCPMomAP</td>\n",
       "      <td>94794</td>\n",
       "      <td>12/03/2017</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCPMomAP</td>\n",
       "      <td>116769</td>\n",
       "      <td>12/19/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCPMomAP</td>\n",
       "      <td>155866</td>\n",
       "      <td>02/19/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCPMomAP</td>\n",
       "      <td>156965</td>\n",
       "      <td>11/26/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project Abbreviation Participant ID Date of Intake FRU0100 FRU0200 FRU0300  \\\n",
       "0             BCPMomAP          11370     11/29/2017   1.500       0       0   \n",
       "1             BCPMomAP          94794     12/03/2017   0.012       0       0   \n",
       "2             BCPMomAP         116769     12/19/2017       0       0       0   \n",
       "3             BCPMomAP         155866     02/19/2018       0       0       0   \n",
       "4             BCPMomAP         156965     11/26/2017       0       0       0   \n",
       "\n",
       "  FRU0400 FRU0500 FRU0600 FRU0700  ... MSC0300 MSC0400 MSC0500 MSC0600  \\\n",
       "0   0.500       0       0       0  ...       0       0       0       0   \n",
       "1       0   0.354       0       0  ...       0       0   0.360       0   \n",
       "2       0       0       0       0  ...   0.907       0       0       0   \n",
       "3   0.800   0.907       0       0  ...       0       0       0       0   \n",
       "4       0       0       0       0  ...   0.250   0.630   0.117       0   \n",
       "\n",
       "  MSC0700 MSC0800 MSC0900 MSC1000 GRW1300 GRS1300  \n",
       "0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       0  \n",
       "4       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = []            \n",
    "for file in file_dict[\"set_09\"][\"mom\"][\"files\"]:\n",
    "    temp_df = pd.read_csv(file,encoding='latin1', sep=\"\\t\")\n",
    "#     print(\"Loading file {}...........Dataframe size: {}\".format(file.split(\"/\")[-1], temp_df.shape))\n",
    "    temp_df=temp_df.drop([0])\n",
    "    for val in temp_df[\"Participant ID\"]:\n",
    "        _id = str(val).strip(\"0\").strip(\".\").split(\"_\")[0]\n",
    "        #print(_id)\n",
    "        temp_df.replace(val, _id, inplace=True)\n",
    "    #print(updated_df[\"Participant ID\"])\n",
    "    temp_list.append(temp_df)\n",
    "dfm9_original = pd.concat(temp_list, ignore_index=True)\n",
    "dfm9_orignal = dfm9_original.sort_values(by=\"Participant ID\")\n",
    "print(\"Final dataframe size: \", dfm9_original.shape)\n",
    "dfm9_original.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_filepath = os.path.join(basepath,'Concat','Mom_BCP_dataset4.txt')\n",
    "dfm4_original.to_csv(concat_filepath, index=False, sep=\"\\t\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_filepath = os.path.join(basepath,'Concat','Mom_BCP_dataset9.txt')\n",
    "dfm9_original.to_csv(concat_filepath, index=False, sep=\"\\t\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfm4_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stupid fucking commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dfm4_original:\n",
    "    if dfm4_original[col].dtype == np.object_:\n",
    "        dfm4_original[col] = (dfm4_original[col].replace(',','.', regex=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_dict = {'hei_totveg': {'parameters':[1.1], 'name': 'HEIX1_TOTALVEG'}, \n",
    "             'hei_greensbeans': {'parameters':[0.2], 'name': 'HEIX2_GREEN_AND_BEAN'},\n",
    "             'hei_totfruit': {'parameters':[0.8], 'name': 'HEIX3_TOTALFRUIT'},\n",
    "             'hei_wholefruit': {'parameters':[0.4], 'name': 'HEIX4_WHOLEFRUIT'},\n",
    "             'hei_wholegrains': {'parameters':[1.5], 'name': 'HEIX5_WHOLEGRAIN'},             \n",
    "             'hei_dairy': {'parameters':[1.3], 'name': 'HEIX6_TOTALDAIRY'},\n",
    "             'hei_totproteins': {'parameters':[2.5], 'name': 'HEIX7_TOTPROT'},\n",
    "             'hei_seafoodplantprot': {'parameters':[0.8], 'name': 'HEIX8_SEAPLANT_PROT'},\n",
    "             'hei_refinedgrains': {'parameters':[1.8,4.3], 'name': 'HEIX11_REFINEDGRAIN'},\n",
    "             'hei_addedsugars': {'parameters':[6.5,26], 'name': 'HEIX12_ADDEDSUGARS'},\n",
    "             'hei_SFA': {'parameters':[8,16], 'name': 'HEIX13_SATFATS'},\n",
    "             'Fats': {'parameters':[1.2,2.5], 'name': 'HEIX9_FATTYACID'},\n",
    "             'hei_sodium':{'parameters':[1.1,2.0],'name':'HEIX10_SODIUM'}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hei_dict={'hei_totveg':\n",
    "          ['VEG0100','VEG0200','VEG0300','VEG0400','VEG0800','VEG0450','VEG0700','VEG0600','VEG0900','VEG0500'],\n",
    "          'hei_greensbeans':\n",
    "          ['VEG0100','VEG0700'],\n",
    "          'hei_totfruit':\n",
    "          ['FRU0100','FRU0200','FRU0300','FRU0400','FRU0500','FRU0600','FRU0700'],\n",
    "          'hei_wholefruit':\n",
    "          ['FRU0300','FRU0400','FRU0500','FRU0600','FRU0700'],\n",
    "          'hei_wholegrains':\n",
    "          ['Whole Grains (ounce equivalents)'],\n",
    "          'hei_dairy':\n",
    "          ['DMF0100','DMR0100','DML0100','DMN0100','DMF0200','DMR0200','DML0200',\n",
    "                       'DML0300','DML0400','DCF0100','DCR0100','DCL0100','DCN0100','DYF0100',\n",
    "                       'DYR0100','DYL0100','DYF0200','DYR0200','DYL0200','DYN0100',\n",
    "                       'DOT0300','DOT0400','DOT0500','DOT0600','DOT0100'],\n",
    "          'hei_totproteins':\n",
    "          ['MRF0100','MRL0100','MRF0200','MRL0200','MRF0300','MRL0300','MRF0400',\n",
    "                             'MRL0400','MCF0200','MCL0200','MRF0500','MPF0100','MPL0100','MPF0200',\n",
    "                             'MFF0100','MFL0100','MFF0200','MSL0100',\n",
    "                             'MSF0100','MCF0100','MCL0100','MOF0100','MOF0200','MOF0300','MOF0400','MOF0500',\n",
    "                             'MOF0600','MOF0700','VEG0700'],\n",
    "          'hei_seafoodplantprot':\n",
    "          ['MFF0100','MFL0100','MFF0200','MSL0100','MSF0100','MOF0500','MOF0600','MOF0700','VEG0700'],\n",
    "          'hei_sodium':\n",
    "          ['Sodium (mg)'],\n",
    "          'hei_refinedgrains':\n",
    "          ['Refined Grains (ounce equivalents)'],\n",
    "          'hei_addedsugars':\n",
    "          ['Added Sugars (by Total Sugars) (g)'], \n",
    "          'ripctsfa': ['% Calories from SFA','Energy (kcal)'],\n",
    "         'energy':\n",
    "         ['Energy (kcal)'],\n",
    "         'fats':\n",
    "         ['Total Polyunsaturated Fatty Acids (PUFA) (g)','Total Monounsaturated Fatty Acids (MUFA) (g)',\n",
    "         'Total Saturated Fatty Acids (SFA) (g)']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hei_totveg', 'hei_greensbeans', 'hei_totfruit', 'hei_wholefruit', 'hei_wholegrains', 'hei_dairy', 'hei_totproteins', 'hei_seafoodplantprot', 'hei_sodium', 'hei_refinedgrains', 'hei_addedsugars', 'ripctsfa', 'energy', 'fats'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hei_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei_totveg\n",
      "hei_greensbeans\n",
      "hei_totfruit\n",
      "hei_wholefruit\n",
      "hei_wholegrains\n",
      "hei_dairy\n",
      "hei_totproteins\n",
      "hei_seafoodplantprot\n",
      "hei_sodium\n",
      "hei_refinedgrains\n",
      "hei_addedsugars\n",
      "ripctsfa\n",
      "energy\n",
      "fats\n"
     ]
    }
   ],
   "source": [
    "for key, value in hei_dict.items():\n",
    "    print(key)\n",
    "    if key in ['hei_totveg','hei_greensbeans','hei_totfruit', 'hei_wholefruit']:\n",
    "        x=value\n",
    "        dfm9_original[key] = dfm9_original[x].astype('float').sum(axis=1)\n",
    "        dfm9_original[key] = dfm9_original[key]/2\n",
    "    if key in ['hei_wholegrains','hei_refinedgrains']:\n",
    "        x=value\n",
    "        dfm4_original[key] = dfm4_original[x].astype('float')\n",
    "    if key in ['hei_dairy']:\n",
    "        x=value[:-1]\n",
    "        tmp= dfm9_original[x].astype('float').sum(axis=1)\n",
    "        y=value[-1]\n",
    "        if y == 'DOT0100':\n",
    "            tmp2=dfm9_original[y].astype('float')/3\n",
    "            dfm9_original[key]=tmp+tmp2\n",
    "        else:\n",
    "            print('NO DAIRY MISSING DOT0100, needs to be last in list')\n",
    "    if key in ['hei_totproteins']:\n",
    "        x=value[:-1]\n",
    "        tmp= dfm9_original[x].astype('float').sum(axis=1)\n",
    "        y=value[-1]\n",
    "        if y == 'VEG0700':\n",
    "            tmp2=dfm9_original[y].astype('float')*2\n",
    "            dfm9_original[key]=tmp+tmp2\n",
    "        else:\n",
    "            print('NO TOTAL PROTEIN MISSING VEG0700, needs to be last in list')\n",
    "    if key in ['hei_seafoodplantprot']:\n",
    "        x=value[:-1]\n",
    "        tmp= dfm9_original[x].astype('float').sum(axis=1)\n",
    "        y=value[-1]\n",
    "        if y == 'VEG0700':\n",
    "            tmp2=dfm9_original[y].astype('float')*2\n",
    "            dfm9_original[key]=tmp+tmp2\n",
    "        else:\n",
    "            print('NO SEAFOOD AND PLANT PROTEIN MISSING VEG0700, needs to be last in list')\n",
    "    if key in ['hei_sodium']:\n",
    "        x=value\n",
    "        dfm4_original[key] = dfm4_original[x].astype('float')/1000\n",
    "    if key in ['hei_addedsugars']:\n",
    "        x=value\n",
    "        dfm4_original[key] = dfm4_original[x].astype('float')*4\n",
    "    if key in ['ripctsfa']:\n",
    "        x=value[0]\n",
    "        y=value[1]\n",
    "        dfm4_original[key] = dfm4_original[x].astype('float')*dfm4_original[y].astype('float')\n",
    "    if key in ['energy']:\n",
    "        x=value\n",
    "        dfm4_original[key] = dfm4_original[x].astype('float')/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adeq_check(inputt, output, parameter):\n",
    "    if inputt in ['hei_totveg','hei_greensbeans', 'hei_totfruit', 'hei_wholefruit', 'hei_totproteins', 'hei_seafoodplantprot']:\n",
    "        tmp = dfm9_original[inputt]/dfm4_original['energy']\n",
    "        dfm9_original[output] = [5 if x >= parameter else 5*(x/parameter) for x in tmp]\n",
    "    elif inputt in ['hei_wholegrains', 'hei_dairy']:\n",
    "        if inputt == 'hei_wholegrains':\n",
    "            tmp = dfm4_original[inputt]/dfm4_original['energy']\n",
    "            dfm4_original[output] = [10 if x >= parameter else 10*(x/parameter) for x in tmp]\n",
    "        else:\n",
    "            tmp = dfm9_original[inputt]/dfm4_original['energy']\n",
    "            dfm9_original[output] = [10 if x >= parameter else 10*(x/parameter) for x in tmp]\n",
    "    elif inputt in ['Fats']:\n",
    "        pdb.set_trace()\n",
    "        FARMIN=parameter[0]\n",
    "        FARMAX=parameter[1]\n",
    "        tmp=dfm4_original['Total Polyunsaturated Fatty Acids (PUFA) (g)']+dfm4_original['Total Monounsaturated Fatty Acids (MUFA) (g)']\n",
    "        tmp2=tmp/dfm4_original['Total Saturated Fatty Acids (SFA) (g)']\n",
    "        dfm4_original[output] = [10 if x > FARMAX else 0 if x <= FARMIN else 10*((x-FARMIN)/(FARMAX-FARMIN)) for x in tmp2]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_check(inputt, output, parameter):    \n",
    "    if inputt in ['hei_sodium','hei_refinedgrains']:\n",
    "        tmp = dfm4_original[inputt]/dfm4_original['energy']\n",
    "        dfm4_original[output] = [0 if x >= parameter[1] else 10 if x <= parameter[0] else 10-(10*((x-parameter[0])/(parameter[1]-parameter[0]))) for x in tmp]\n",
    "    if inputt in ['hei_addedsugars']:\n",
    "        tmp= 100*dfm4_original[inputt]/dfm4_original['energy']\n",
    "        dfm4_original[output] = [0 if x >= parameter[1] else 10 if x < parameter[0] else 10-(10*((x-parameter[0])/(parameter[1]-parameter[0]))) for x in tmp]\n",
    "    if inputt in ['hei_SFA']:\n",
    "        tmp= dfm4_original['% Calories from SFA']\n",
    "        dfm4_original[output] = [0 if x > parameter[1] else 10 if x < parameter[0] else 10-(10*((x-parameter[0])/(parameter[1]-parameter[0]))) for x in tmp]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(x):\n",
    "    for key,values in x.items():\n",
    "        print('Calculating score for %s'%key)\n",
    "        if key in ['hei_totveg','hei_greensbeans', 'hei_totfruit', 'hei_wholefruit', 'hei_totproteins', 'hei_seafoodplantprot',\n",
    "                    'hei_wholegrains', 'hei_dairy','Fats']:\n",
    "            if key == 'Fats':\n",
    "                adeq_check(key, values['name'], values['parameters'])\n",
    "            else:\n",
    "                adeq_check(key, values['name'], values['parameters'][0])\n",
    "        if key in ['hei_sodium','hei_refinedgrains','hei_addedsugars','hei_SFA']:\n",
    "            mod_check(key, values['name'], values['parameters'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for hei_totveg\n",
      "Calculating score for hei_greensbeans\n",
      "Calculating score for hei_totfruit\n",
      "Calculating score for hei_wholefruit\n",
      "Calculating score for hei_wholegrains\n",
      "hi\n",
      "Calculating score for hei_dairy\n",
      "ho\n",
      "Calculating score for hei_totproteins\n",
      "Calculating score for hei_seafoodplantprot\n",
      "Calculating score for hei_refinedgrains\n",
      "Calculating score for hei_addedsugars\n",
      "Calculating score for hei_SFA\n",
      "Calculating score for Fats\n",
      "> <ipython-input-14-5dda28135ca8>(16)adeq_check()\n",
      "-> FARMIN=parameter[0]\n",
      "(Pdb) parameter\n",
      "[1.2, 2.5]\n",
      "(Pdb) c\n",
      "Calculating score for hei_sodium\n"
     ]
    }
   ],
   "source": [
    "check(para_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Abbreviation',\n",
       " 'Participant ID',\n",
       " 'Date of Intake',\n",
       " 'FRU0100',\n",
       " 'FRU0200',\n",
       " 'FRU0300',\n",
       " 'FRU0400',\n",
       " 'FRU0500',\n",
       " 'FRU0600',\n",
       " 'FRU0700',\n",
       " 'VEG0100',\n",
       " 'VEG0200',\n",
       " 'VEG0300',\n",
       " 'VEG0400',\n",
       " 'VEG0800',\n",
       " 'VEG0450',\n",
       " 'VEG0700',\n",
       " 'VEG0600',\n",
       " 'VEG0900',\n",
       " 'VEG0500',\n",
       " 'FMC0100',\n",
       " 'GRW0100',\n",
       " 'GRS0100',\n",
       " 'GRR0100',\n",
       " 'GRW0200',\n",
       " 'GRS0200',\n",
       " 'GRR0200',\n",
       " 'GRW0300',\n",
       " 'GRS0300',\n",
       " 'GRR0300',\n",
       " 'GRW0400',\n",
       " 'GRS0400',\n",
       " 'GRR0400',\n",
       " 'GRW0500',\n",
       " 'GRS0500',\n",
       " 'GRR0500',\n",
       " 'GRW0600',\n",
       " 'GRS0600',\n",
       " 'GRR0600',\n",
       " 'GRW0700',\n",
       " 'GRS0700',\n",
       " 'GRR0700',\n",
       " 'GRW0800',\n",
       " 'GRS0800',\n",
       " 'GRR0800',\n",
       " 'GRW1000',\n",
       " 'GRS1000',\n",
       " 'GRR1000',\n",
       " 'GRW0900',\n",
       " 'GRS0900',\n",
       " 'GRR0900',\n",
       " 'GRW1100',\n",
       " 'GRW1200',\n",
       " 'GRR1300',\n",
       " 'MRF0100',\n",
       " 'MRL0100',\n",
       " 'MRF0200',\n",
       " 'MRL0200',\n",
       " 'MRF0300',\n",
       " 'MRL0300',\n",
       " 'MRF0400',\n",
       " 'MRL0400',\n",
       " 'MCF0200',\n",
       " 'MCL0200',\n",
       " 'MRF0500',\n",
       " 'MPF0100',\n",
       " 'MPL0100',\n",
       " 'MPF0200',\n",
       " 'MFF0100',\n",
       " 'MFL0100',\n",
       " 'MFF0200',\n",
       " 'MSL0100',\n",
       " 'MSF0100',\n",
       " 'MCF0100',\n",
       " 'MCL0100',\n",
       " 'MOF0100',\n",
       " 'MOF0200',\n",
       " 'FMC0200',\n",
       " 'MOF0300',\n",
       " 'MOF0400',\n",
       " 'MOF0500',\n",
       " 'MOF0600',\n",
       " 'MOF0700',\n",
       " 'DMF0100',\n",
       " 'DMR0100',\n",
       " 'DML0100',\n",
       " 'DMN0100',\n",
       " 'DMF0200',\n",
       " 'DMR0200',\n",
       " 'DML0200',\n",
       " 'DML0300',\n",
       " 'DML0400',\n",
       " 'SWT0600',\n",
       " 'MSC1100',\n",
       " 'DCF0100',\n",
       " 'DCR0100',\n",
       " 'DCL0100',\n",
       " 'DCN0100',\n",
       " 'DYF0100',\n",
       " 'DYR0100',\n",
       " 'DYL0100',\n",
       " 'DYF0200',\n",
       " 'DYR0200',\n",
       " 'DYL0200',\n",
       " 'DYN0100',\n",
       " 'DOT0100',\n",
       " 'DOT0200',\n",
       " 'DOT0300',\n",
       " 'DOT0400',\n",
       " 'FCF0100',\n",
       " 'FCR0100',\n",
       " 'FCL0100',\n",
       " 'FCN0100',\n",
       " 'DOT0500',\n",
       " 'DOT0600',\n",
       " 'DOT0700',\n",
       " 'DOT0800',\n",
       " 'FMF0100',\n",
       " 'FMR0100',\n",
       " 'FOF0100',\n",
       " 'FSF0100',\n",
       " 'FAF0100',\n",
       " 'FAR0100',\n",
       " 'FDF0100',\n",
       " 'FDR0100',\n",
       " 'SWT0400',\n",
       " 'MSC1200',\n",
       " 'SWT0500',\n",
       " 'SWT0700',\n",
       " 'SWT0800',\n",
       " 'SWT0100',\n",
       " 'SWT0200',\n",
       " 'SWT0300',\n",
       " 'BVS0400',\n",
       " 'BVA0400',\n",
       " 'BVU0300',\n",
       " 'BVS0300',\n",
       " 'BVA0300',\n",
       " 'BVS0500',\n",
       " 'BVA0500',\n",
       " 'BVU0400',\n",
       " 'BVS0100',\n",
       " 'BVA0100',\n",
       " 'BVU0100',\n",
       " 'BVS0200',\n",
       " 'BVA0200',\n",
       " 'BVU0200',\n",
       " 'BVS0600',\n",
       " 'BVA0600',\n",
       " 'BVU0500',\n",
       " 'BVS0700',\n",
       " 'BVA0700',\n",
       " 'BVU0600',\n",
       " 'BVO0100',\n",
       " 'BVO0200',\n",
       " 'BVE0100',\n",
       " 'BVE0400',\n",
       " 'BVE0300',\n",
       " 'BVE0200',\n",
       " 'MSC0100',\n",
       " 'MSC0200',\n",
       " 'MSC0300',\n",
       " 'MSC0400',\n",
       " 'MSC0500',\n",
       " 'MSC0600',\n",
       " 'MSC0700',\n",
       " 'MSC0800',\n",
       " 'MSC0900',\n",
       " 'MSC1000',\n",
       " 'GRW1300',\n",
       " 'GRS1300',\n",
       " 'hei_totveg',\n",
       " 'hei_greensbeans',\n",
       " 'hei_totfruit',\n",
       " 'hei_wholefruit',\n",
       " 'hei_dairy',\n",
       " 'hei_totproteins',\n",
       " 'hei_seafoodplantprot',\n",
       " 'HEIX1_TOTALVEG',\n",
       " 'HEIX2_GREEN_AND_BEAN',\n",
       " 'HEIX3_TOTALFRUIT',\n",
       " 'HEIX4_WHOLEFRUIT',\n",
       " 'HEIX6_TOTALDAIRY',\n",
       " 'HEIX7_TOTPROT',\n",
       " 'HEIX8_SEAPLANT_PROT']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfm9_original.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Abbreviation',\n",
       " 'Participant ID',\n",
       " 'Date of Intake',\n",
       " 'Project Name',\n",
       " 'Record Type',\n",
       " 'Participant Name',\n",
       " 'Gender',\n",
       " 'Date of Birth',\n",
       " 'Date of Entry',\n",
       " 'Day of Intake',\n",
       " 'Visit Number',\n",
       " 'Interviewer ID',\n",
       " 'Site ID',\n",
       " 'DRI Life Stage Group or RDA Category',\n",
       " 'Intake Amount',\n",
       " 'Intake Reliability',\n",
       " 'Data Collected in NCC Database Version',\n",
       " 'Data Collected in Software Version',\n",
       " 'Total Grams',\n",
       " 'Energy (kcal)',\n",
       " 'Total Fat (g)',\n",
       " 'Total Carbohydrate (g)',\n",
       " 'Total Protein (g)',\n",
       " 'Animal Protein (g)',\n",
       " 'Vegetable Protein (g)',\n",
       " 'Alcohol (g)',\n",
       " 'Cholesterol (mg)',\n",
       " 'Total Saturated Fatty Acids (SFA) (g)',\n",
       " 'Total Monounsaturated Fatty Acids (MUFA) (g)',\n",
       " 'Total Polyunsaturated Fatty Acids (PUFA) (g)',\n",
       " 'Fructose (g)',\n",
       " 'Galactose (g)',\n",
       " 'Glucose (g)',\n",
       " 'Lactose (g)',\n",
       " 'Maltose (g)',\n",
       " 'Sucrose (g)',\n",
       " 'Starch (g)',\n",
       " 'Total Dietary Fiber (g)',\n",
       " 'Soluble Dietary Fiber (g)',\n",
       " 'Insoluble Dietary Fiber (g)',\n",
       " 'Pectins (g)',\n",
       " 'Total Vitamin A Activity (International Units) (IU)',\n",
       " 'Beta-Carotene Equivalents (derived from provitamin A carotenoids) (mcg)',\n",
       " 'Retinol (mcg)',\n",
       " 'Vitamin D (calciferol) (mcg)',\n",
       " 'Total Alpha-Tocopherol Equivalents (mg)',\n",
       " 'Vitamin E (Total Alpha-Tocopherol) (mg)',\n",
       " 'Beta-Tocopherol (mg)',\n",
       " 'Gamma-Tocopherol (mg)',\n",
       " 'Delta-Tocopherol (mg)',\n",
       " 'Vitamin K (phylloquinone) (mcg)',\n",
       " 'Vitamin C (ascorbic acid) (mg)',\n",
       " 'Thiamin (vitamin B1) (mg)',\n",
       " 'Riboflavin (vitamin B2) (mg)',\n",
       " 'Niacin (vitamin B3) (mg)',\n",
       " 'Pantothenic Acid (mg)',\n",
       " 'Vitamin B-6 (pyridoxine, pyridoxyl, & pyridoxamine) (mg)',\n",
       " 'Total Folate (mcg)',\n",
       " 'Vitamin B-12 (cobalamin) (mcg)',\n",
       " 'Calcium (mg)',\n",
       " 'Phosphorus (mg)',\n",
       " 'Magnesium (mg)',\n",
       " 'Iron (mg)',\n",
       " 'Zinc (mg)',\n",
       " 'Copper (mg)',\n",
       " 'Selenium (mcg)',\n",
       " 'Sodium (mg)',\n",
       " 'Potassium (mg)',\n",
       " 'SFA 4:0 (butyric acid) (g)',\n",
       " 'SFA 6:0 (caproic acid) (g)',\n",
       " 'SFA 8:0 (caprylic acid) (g)',\n",
       " 'SFA 10:0 (capric acid) (g)',\n",
       " 'SFA 12:0 (lauric acid) (g)',\n",
       " 'SFA 14:0 (myristic acid) (g)',\n",
       " 'SFA 16:0 (palmitic acid) (g)',\n",
       " 'SFA 17:0 (margaric acid) (g)',\n",
       " 'SFA 18:0 (stearic acid) (g)',\n",
       " 'SFA 20:0 (arachidic acid) (g)',\n",
       " 'SFA 22:0 (behenic acid) (g)',\n",
       " 'MUFA 14:1 (myristoleic acid) (g)',\n",
       " 'MUFA 16:1 (palmitoleic acid) (g)',\n",
       " 'MUFA 18:1 (oleic acid) (g)',\n",
       " 'MUFA 20:1 (gadoleic acid) (g)',\n",
       " 'MUFA 22:1 (erucic acid) (g)',\n",
       " 'PUFA 18:2 (linoleic acid) (g)',\n",
       " 'PUFA 18:3 (linolenic acid) (g)',\n",
       " 'PUFA 18:4 (parinaric acid) (g)',\n",
       " 'PUFA 20:4 (arachidonic acid) (g)',\n",
       " 'PUFA 20:5 (eicosapentaenoic acid [EPA]) (g)',\n",
       " 'PUFA 22:5 (docosapentaenoic acid [DPA]) (g)',\n",
       " 'PUFA 22:6 (docosahexaenoic acid [DHA]) (g)',\n",
       " 'Tryptophan (g)',\n",
       " 'Threonine (g)',\n",
       " 'Isoleucine (g)',\n",
       " 'Leucine (g)',\n",
       " 'Lysine (g)',\n",
       " 'Methionine (g)',\n",
       " 'Cystine (g)',\n",
       " 'Phenylalanine (g)',\n",
       " 'Tyrosine (g)',\n",
       " 'Valine (g)',\n",
       " 'Arginine (g)',\n",
       " 'Histidine (g)',\n",
       " 'Alanine (g)',\n",
       " 'Aspartic Acid (g)',\n",
       " 'Glutamic Acid (g)',\n",
       " 'Glycine (g)',\n",
       " 'Proline (g)',\n",
       " 'Serine (g)',\n",
       " 'Aspartame (mg)',\n",
       " 'Saccharin (mg)',\n",
       " 'Caffeine (mg)',\n",
       " 'Phytic Acid (mg)',\n",
       " 'Oxalic Acid (mg)',\n",
       " '3-Methylhistidine (mg)',\n",
       " 'Sucrose Polyester (g)',\n",
       " 'Ash (g)',\n",
       " 'Water (g)',\n",
       " '% Calories from Fat',\n",
       " '% Calories from Carbohydrate',\n",
       " '% Calories from Protein',\n",
       " '% Calories from Alcohol',\n",
       " '% Calories from SFA',\n",
       " '% Calories from MUFA',\n",
       " '% Calories from PUFA',\n",
       " 'Polyunsaturated to Saturated Fat Ratio',\n",
       " 'Cholesterol to Saturated Fatty Acid Index',\n",
       " 'Total Vitamin A Activity (Retinol Equivalents) (mcg)',\n",
       " 'TRANS 18:1 (trans-octadecenoic acid) (g)',\n",
       " 'TRANS 18:2 (trans-octadecadienoic acid) (g)',\n",
       " 'TRANS 16:1 (trans-hexadecenoic acid) (g)',\n",
       " 'Total Trans-Fatty Acids (TRANS) (g)',\n",
       " 'User Nutrient 1 (mg)',\n",
       " 'User Nutrient 2 (mg)',\n",
       " 'User Nutrient 3 (mg)',\n",
       " 'User Nutrient 4 (mg)',\n",
       " 'User Nutrient 5 (mg)',\n",
       " 'User Nutrient 6 (mg)',\n",
       " 'User Nutrient 7 (mg)',\n",
       " 'User Nutrient 8 (mg)',\n",
       " 'User Nutrient 9 (mg)',\n",
       " 'User Nutrient 10 (mg)',\n",
       " 'Header Notes',\n",
       " 'Beta-Carotene (provitamin A carotenoid) (mcg)',\n",
       " 'Alpha-Carotene (provitamin A carotenoid) (mcg)',\n",
       " 'Beta-Cryptoxanthin (provitamin A carotenoid) (mcg)',\n",
       " 'Lutein + Zeaxanthin (mcg)',\n",
       " 'Lycopene (mcg)',\n",
       " 'Dietary Folate Equivalents (mcg)',\n",
       " 'Natural Folate (food folate) (mcg)',\n",
       " 'Synthetic Folate (folic acid) (mcg)',\n",
       " 'Data Generated in NCC Database Version',\n",
       " 'Data Generated in Software Version',\n",
       " 'Trailer Notes',\n",
       " 'User Nutrient 11 (mg)',\n",
       " 'User Nutrient 12 (mg)',\n",
       " 'User Nutrient 13 (mg)',\n",
       " 'User Nutrient 14 (mg)',\n",
       " 'User Nutrient 15 (mg)',\n",
       " 'User Nutrient 16 (mg)',\n",
       " 'User Nutrient 17 (mg)',\n",
       " 'User Nutrient 18 (mg)',\n",
       " 'User Nutrient 19 (mg)',\n",
       " 'User Nutrient 20 (mg)',\n",
       " 'Total Vitamin A Activity (Retinol Activity Equivalents) (mcg)',\n",
       " 'Energy (kj)',\n",
       " 'Niacin Equivalents (mg)',\n",
       " 'Total Sugars (g)',\n",
       " 'Omega-3 Fatty Acids (g)',\n",
       " 'Manganese (mg)',\n",
       " 'Vitamin E (International Units) (IU)',\n",
       " 'Natural Alpha-Tocopherol (RRR-alpha-tocopherol or d-alpha-tocopherol) (mg)',\n",
       " 'Synthetic Alpha-Tocopherol (all rac-alpha-tocopherol or dl-alpha-tocopherol) (mg)',\n",
       " 'Daidzein (mg)',\n",
       " 'Genistein (mg)',\n",
       " 'Glycitein (mg)',\n",
       " 'Coumestrol (mg)',\n",
       " 'Biochanin A (mg)',\n",
       " 'Formononetin (mg)',\n",
       " 'Column intentionally left blank',\n",
       " 'Column intentionally left blank.1',\n",
       " 'Column intentionally left blank.2',\n",
       " 'Column intentionally left blank.3',\n",
       " 'Added Sugars (by Available Carbohydrate) (g)',\n",
       " 'Acesulfame Potassium (mg)',\n",
       " 'Sucralose (mg)',\n",
       " 'Available Carbohydrate (g)',\n",
       " 'Glycemic Index (glucose reference)',\n",
       " 'Glycemic Index (bread reference)',\n",
       " 'Glycemic Load (glucose reference)',\n",
       " 'Glycemic Load (bread reference)',\n",
       " 'Choline (mg)',\n",
       " 'Betaine (mg)',\n",
       " 'Erythritol (g)',\n",
       " 'Inositol (g)',\n",
       " 'Isomalt (g)',\n",
       " 'Lactitol (g)',\n",
       " 'Maltitol (g)',\n",
       " 'Mannitol (g)',\n",
       " 'Pinitol (g)',\n",
       " 'Sorbitol (g)',\n",
       " 'Xylitol (g)',\n",
       " 'Nitrogen (g)',\n",
       " 'Total Conjugated Linoleic Acid (CLA 18:2) (g)',\n",
       " 'CLA cis-9, trans-11 (g)',\n",
       " 'CLA trans-10, cis-12 (g)',\n",
       " 'Tagatose (mg)',\n",
       " 'Vitamin D2 (ergocalciferol) (mcg)',\n",
       " 'Vitamin D3 (cholecalciferol) (mcg)',\n",
       " 'Added Sugars (by Total Sugars) (g)',\n",
       " 'Total Grains (ounce equivalents)',\n",
       " 'Whole Grains (ounce equivalents)',\n",
       " 'Refined Grains (ounce equivalents)',\n",
       " 'PUFA 18:3 n-3 (alpha-linolenic acid [ALA]) (g)',\n",
       " 'Solid Fats (g)',\n",
       " 'Gluten (g)',\n",
       " 'Data Field 1 Descriptor',\n",
       " 'Data Field 1 Response',\n",
       " 'Data Field 2 Descriptor',\n",
       " 'Data Field 2 Response',\n",
       " 'Data Field 3 Descriptor',\n",
       " 'Data Field 3 Response',\n",
       " 'Data Field 4 Descriptor',\n",
       " 'Data Field 4 Response',\n",
       " 'Data Field 5 Descriptor',\n",
       " 'Data Field 5 Response',\n",
       " 'hei_wholegrains',\n",
       " 'hei_sodium',\n",
       " 'hei_refinedgrains',\n",
       " 'hei_addedsugars',\n",
       " 'ripctsfa',\n",
       " 'energy',\n",
       " 'HEIX5_WHOLEGRAIN',\n",
       " 'HEIX11_REFINEDGRAIN',\n",
       " 'HEIX12_ADDEDSUGARS',\n",
       " 'HEIX13_SATFATS',\n",
       " 'HEIX9_FATTYACID',\n",
       " 'HEIX10_SODIUM']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfm4_original.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Columns with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = dfm4_original[dfm4_original.isna().any(axis=1)]\n",
    "for a in dfm4_original: \n",
    "       if dfm4_original[a].isna().any(axis=0) == True:\n",
    "            #print(dfm4_original[a].head(30))\n",
    "            del dfm4_original[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm4_original.empty\n",
    "np.where(pd.isnull(dfm4_original))\n",
    "np.where(dfm4_original.applymap(lambda x: x == ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Relevant Rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []            \n",
    "for file in file_dict[\"set_04\"][\"mom\"][\"files\"]:\n",
    "    temp_df = pd.read_csv(file,encoding='latin1', sep=\"\\t\")\n",
    "    print(\"Loading file {}...........Dataframe size: {}\".format(file.split(\"/\")[-1], temp_df.shape))\n",
    "    updated_df = temp_df[[\"Participant ID\", \"Date of Intake\", \"Day of Intake\", \"Visit Number\", \"Site ID\", \"Total Grams\", \"Energy (kcal)\", \"Total Fat (g)\", \n",
    "                  \"Total Carbohydrate (g)\", \"Total Protein (g)\", \"Animal Protein (g)\", \"Vegetable Protein (g)\", \"Cholesterol (mg)\", \n",
    "                  \"Total Saturated Fatty Acids (SFA) (g)\", \"Total Monounsaturated Fatty Acids (MUFA) (g)\", \"Total Polyunsaturated Fatty Acids (PUFA) (g)\", \n",
    "                  \"Total Vitamin A Activity (International Units) (IU)\", \"Vitamin D (calciferol) (mcg)\", \"Galactose (g)\", \"Glucose (g)\", \"Lactose (g)\", \n",
    "                  \"Maltose (g)\", \"Sucrose (g)\", \"Total Dietary Fiber (g)\", \"Soluble Dietary Fiber (g)\", \"Insoluble Dietary Fiber (g)\", \"Total Folate (mcg)\", \n",
    "                  \"Vitamin B-12 (cobalamin) (mcg)\", \"Magnesium (mg)\", \"Iron (mg)\", \"Zinc (mg)\", \"Copper (mg)\", \"Selenium (mcg)\", \"PUFA 20:4 (arachidonic acid) (g)\", \n",
    "                  \"PUFA 20:5 (eicosapentaenoic acid [EPA]) (g)\", \"PUFA 22:6 (docosahexaenoic acid [DHA]) (g)\", \"Tryptophan (g)\", \"Threonine (g)\", \"Isoleucine (g)\",\n",
    "                  \"Leucine (g)\", \"Lysine (g)\", \"Methionine (g)\", \"Cystine (g)\", \"Phenylalanine (g)\", \"Tyrosine (g)\", \"Valine (g)\", \"Arginine (g)\", \"Histidine (g)\",\n",
    "                  \"Alanine (g)\", \"Aspartic Acid (g)\", \"Glutamic Acid (g)\", \"Glycine (g)\", \"Proline (g)\", \"Serine (g)\", \"Aspartame (mg)\", \"Saccharin (mg)\", \"Caffeine (mg)\",\n",
    "                  \"Oxalic Acid (mg)\", \"Water (g)\", \"% Calories from Fat\", \"% Calories from Carbohydrate\", \"% Calories from Protein\", \"% Calories from Alcohol\", \n",
    "                  \"% Calories from SFA\", \"% Calories from MUFA\", \"% Calories from PUFA\", \"Polyunsaturated to Saturated Fat Ratio\", \"Cholesterol to Saturated Fatty Acid Index\",\n",
    "                  \"Total Vitamin A Activity (Retinol Equivalents) (mcg)\", \"TRANS 18:1 (trans-octadecenoic acid) (g)\", \"TRANS 18:2 (trans-octadecadienoic acid) (g)\", \n",
    "                  \"TRANS 16:1 (trans-hexadecenoic acid) (g)\", \"Total Trans-Fatty Acids (TRANS) (g)\", \"Water (g)\", \"% Calories from Fat\", \"% Calories from Carbohydrate\",\n",
    "                  \"% Calories from Protein\", \"% Calories from Alcohol\", \"% Calories from SFA\", \"% Calories from MUFA\", \"% Calories from PUFA\", \"Polyunsaturated to Saturated Fat Ratio\",\n",
    "                  \"Cholesterol to Saturated Fatty Acid Index\", \"Total Vitamin A Activity (Retinol Equivalents) (mcg)\", \"TRANS 18:1 (trans-octadecenoic acid) (g)\",\n",
    "                  \"TRANS 18:2 (trans-octadecadienoic acid) (g)\", \"TRANS 16:1 (trans-hexadecenoic acid) (g)\", \"Total Trans-Fatty Acids (TRANS) (g)\", \"Beta-Carotene (provitamin A carotenoid) (mcg)\",\n",
    "                  \"Lutein + Zeaxanthin (mcg)\", \"Lycopene (mcg)\", \"Dietary Folate Equivalents (mcg)\", \"Natural Folate (food folate) (mcg)\", \"Synthetic Folate (folic acid) (mcg)\",\n",
    "                  \"Niacin Equivalents (mg)\", \"Total Sugars (g)\", \"Omega-3 Fatty Acids (g)\", \"Manganese (mg)\", \"Vitamin E (International Units) (IU)\", \"Added Sugars (by Available Carbohydrate) (g)\",\n",
    "                  \"Glycemic Index (glucose reference)\", \"Glycemic Load (glucose reference)\", \"Choline (mg)\", \"PUFA 18:3 n-3 (alpha-linolenic acid [ALA]) (g)\"]]\n",
    "    # Update ID to be consistent -- keeping only first 6 digits, no extra \"_\" tags\n",
    "    for val in updated_df[\"Participant ID\"]:\n",
    "        _id = str(val).split(\"_\")[0]\n",
    "        #print(_id)\n",
    "        updated_df.replace(val, _id, inplace=True)\n",
    "    #print(updated_df[\"Participant ID\"])\n",
    "    temp_list.append(updated_df)\n",
    "    #print(file)\n",
    "    #temp_df =  pd.read_csv(file, sep=\"\\t\", encoding='latin1')\n",
    "    #temp_list.append(temp_df)\n",
    "    #print(temp_df.shape)\n",
    "dfm4 = pd.concat(temp_list, ignore_index=True)\n",
    "print(\"Final dataframe size: \", dfm4.shape)\n",
    "dfm4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm4 = dfm4.sort_values(by=\"Participant ID\")\n",
    "dfm4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add mom or child identifier column\n",
    "dfm4[\"Mom(0) or Child(1) ID\"] = 0\n",
    "print(dfm4.shape)\n",
    "dfm4[\"Mom(0) or Child(1) ID\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm4['Sphingomyelin (mg)'] = dfm4[['Choline (mg)']].div(4.366)\n",
    "dfm4['Sphingomyelin (mg)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm4['Phosphatidycholine (mg)'] = dfm4[['Choline (mg)']].multiply(0.479)\n",
    "dfm4['Phosphatidycholine (mg)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df=dfm4.groupby([\"Participant ID\", \"Visit Number\"]).mean(numeric_only=True)\n",
    "#reset index\n",
    "avg_df.reset_index(inplace=True)  \n",
    "avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_filename = \"Mom_BCP_dataset4\"\n",
    "csv_filename = \"{}.csv\".format(concat_filename)\n",
    "tsv_filename = \"{}.tsv\".format(concat_filename)\n",
    "xlsx_filename = \"{}.xlsx\".format(concat_filename)\n",
    "concat_filepath = os.path.join(csv_filename)\n",
    "xlsx_filepath = os.path.join(xlsx_filename)\n",
    "tsv_filepath = os.path.join(tsv_filename)\n",
    "\n",
    "#print( new_filepath)\n",
    "# write concatentation to file\n",
    "writer = pd.ExcelWriter(xlsx_filepath, engine='xlsxwriter')\n",
    "avg_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "#concat_df.to_excel(concat_filepath)\n",
    "avg_df.to_csv(concat_filepath, index=False, sep=\"\\t\", header=True)\n",
    "avg_df.to_csv(tsv_filepath, index=False, sep=\"\\t\", header=True)\n",
    "print(\"Written concat file, \", concat_filepath)\n",
    "#umn_df = final_df[concat_df['Site ID'] == \"UMN\"]\n",
    "#umn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df[\"Participant ID\"].unique()\n",
    "avg_df[\"Day of Intake\"].unique()\n",
    "avg_df.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
