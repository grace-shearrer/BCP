{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data  \n",
    "  \n",
    "Currently our script uses data X,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory path and collect the child and mom files\n",
    "# --> We may need/want to differentiate b/w text files 04 and 09 (both related to Nutrition intake)\n",
    "# --> For `glob` we need to know naming of text files - (any convention?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Files Found:  \n",
      "For Mom: /Users/nikkibytes/Documents/summer2019/example_data/UMNUNCChild04.txt,/Users/nikkibytes/Documents/summer2019/example_data/UMNUNCChild04_.txt \n",
      "For Child: /Users/nikkibytes/Documents/summer2019/example_data/UMNUNCMom04.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir_path = \"/Users/nikkibytes/Documents/summer2019/example_data\"\n",
    "\n",
    "child04_text_files = glob.glob(os.path.join(data_dir_path, \"*Child*04*\"))\n",
    "mom04_text_files = glob.glob(os.path.join(data_dir_path, \"*Mom*04*\"))\n",
    "\n",
    "print(\"Text Files Found:  \\nFor Mom: {} \\nFor Child: {}\".format(','.join(child04_text_files), ','.join(mom04_text_files)))\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Sphingomyelin (mg)', 'Phosphatidycholine (mg)' -- these two not found in current dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Child Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we concatenate the children \n",
    "#\n",
    "\n",
    "df_list = []\n",
    "for file in child04_text_files:\n",
    "    orig_df=pd.read_csv(file, sep=\"\\t\")\n",
    "    updated_df=orig_df[['Participant ID', 'Visit Number', 'Site ID', 'Total Grams',\n",
    "                 'Energy (kcal)', 'Total Fat (g)', 'Total Carbohydrate (g)', \n",
    "                 'Total Protein (g)', 'Animal Protein (g)', 'Vegetable Protein (g)',\n",
    "                 'Cholesterol (mg)', 'Total Saturated Fatty Acids (SFA) (g)',\n",
    "                 'Total Monounsaturated Fatty Acids (MUFA) (g)', 'Total Polyunsaturated Fatty Acids (PUFA) (g)',\n",
    "                 'Total Vitamin A Activity (International Units) (IU)', 'Vitamin D (calciferol) (mcg)', \n",
    "                 'Total Folate (mcg)', 'Vitamin B-12 (cobalamin) (mcg)', 'Magnesium (mg)',\n",
    "                 'Iron (mg)', 'Zinc (mg)', 'Copper (mg)', 'Selenium (mcg)', 'PUFA 20:4 (arachidonic acid) (g)',\n",
    "                 'PUFA 20:5 (eicosapentaenoic acid [EPA]) (g)', 'PUFA 22:6 (docosahexaenoic acid [DHA]) (g)', \n",
    "                 '% Calories from Fat', '% Calories from Carbohydrate', '% Calories from Protein', 'Polyunsaturated to Saturated Fat Ratio',\n",
    "                 'Lutein + Zeaxanthin (mcg)', 'Choline (mg)']]\n",
    "    for val in updated_df[\"Participant ID\"]:\n",
    "        _id = val.split(\"_\")[0]\n",
    "        #print(_id)\n",
    "        updated_df.replace(val, _id, inplace=True)\n",
    "\n",
    "    #print(updated_df.head())\n",
    "    df_list.append(updated_df)\n",
    "    #print(updated_df.shape)\n",
    "\n",
    "\n",
    "print(\"List of dataframes made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_list)\n",
    "concat_df = pd.concat(df_list, ignore_index=True)\n",
    "concat_df = concat_df.sort_values(by=\"Participant ID\")\n",
    "#print(final_df.head())\n",
    "#print(final_df.tail())\n",
    "#print(final_df.shape)\n",
    "concat_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write child concatenated file (all available data on a single spread sheet, with reduced columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_filename = 'Child_concat_test1'\n",
    "csv_filename = \"{}.csv\".format(concat_filename)\n",
    "xlsx_filename = \"{}.xlsx\".format(concat_filename)\n",
    "concat_filepath = os.path.join(data_dir_path, \"outputs\", csv_filename)\n",
    "xlsx_filepath = os.path.join(data_dir_path, \"outputs\", xlsx_filename)\n",
    "\n",
    "\n",
    "#print( new_filepath)\n",
    "# write concatentation to file\n",
    "writer = pd.ExcelWriter(xlsx_filepath, engine='xlsxwriter')\n",
    "concat_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "#concat_df.to_excel(concat_filepath)\n",
    "concat_df.to_csv(concat_filepath, index=False)\n",
    "print(\"Written concat file, \", concat_filepath)\n",
    "umn_df = concat_df[concat_df['Site ID'] == \"UMN\"]\n",
    "umn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umn_df['Total Fat (g)'].plot(kind='hist',colormap=\"plasma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_df = concat_df[concat_df['Site ID'] == \"UNC\"]\n",
    "unc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_df['Total Fat (g)'].plot(kind='hist',colormap=\"plasma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_mean_df=concat_df.groupby(\"Participant ID\").mean()\n",
    "child_mean_df=child_mean_df.drop(columns=\"Visit Number\")\n",
    "child_mean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Site Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_mean_site_df=concat_df.groupby(\"Site ID\").mean()\n",
    "child_mean_site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_df_T = child_mean_site_df.T\n",
    "child_df_T.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_df_T.plot(kind=\"scatter\", x=\"UMN\", y='UNC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write child mean file (all available data on a single spread sheet from concatenated file with subjects averaged across visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_mean_filename = 'Child_mean_test1'\n",
    "csv_filename = \"{}.csv\".format(ch_mean_filename)\n",
    "csv_filepath = os.path.join(data_dir_path, \"outputs\", csv_filename)\n",
    "xlsx_filename = \"{}.xlsx\".format(ch_mean_filename)\n",
    "xlsx_filepath = os.path.join(data_dir_path, \"outputs\", xlsx_filename)\n",
    "\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(xlsx_filepath, engine='xlsxwriter')\n",
    "concat_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "#print( new_filepath)\n",
    "# write concatentation to file\n",
    "child_mean_df.to_csv(xlsx_filepath)\n",
    "print(\"Written mean file, \", xlsx_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_mean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_mean_df['Cholesterol (mg)'].plot(kind='hist',colormap=\"plasma\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_mean_df.plot(kind=\"scatter\", x=\"Copper (mg)\", y='Animal Protein (g)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_umn_df_mean = concat_df[concat_df['Site ID'] == \"UMN\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we concatenate the children \n",
    "# **We won't want the original filename when we concatenate all the files\n",
    "\n",
    "mom_df_list = []\n",
    "for file in mom04_text_files:\n",
    "    orig_df=pd.read_csv(file, sep=\"\\t\")\n",
    "    updated_df=orig_df[['Participant ID', 'Visit Number', 'Site ID', 'Total Grams',\n",
    "                 'Energy (kcal)', 'Total Fat (g)', 'Total Carbohydrate (g)', \n",
    "                 'Total Protein (g)', 'Animal Protein (g)', 'Vegetable Protein (g)',\n",
    "                 'Cholesterol (mg)', 'Total Saturated Fatty Acids (SFA) (g)',\n",
    "                 'Total Monounsaturated Fatty Acids (MUFA) (g)', 'Total Polyunsaturated Fatty Acids (PUFA) (g)',\n",
    "                 'Total Vitamin A Activity (International Units) (IU)', 'Vitamin D (calciferol) (mcg)', \n",
    "                 'Total Folate (mcg)', 'Vitamin B-12 (cobalamin) (mcg)', 'Magnesium (mg)',\n",
    "                 'Iron (mg)', 'Zinc (mg)', 'Copper (mg)', 'Selenium (mcg)', 'PUFA 20:4 (arachidonic acid) (g)',\n",
    "                 'PUFA 20:5 (eicosapentaenoic acid [EPA]) (g)', 'PUFA 22:6 (docosahexaenoic acid [DHA]) (g)', \n",
    "                 '% Calories from Fat', '% Calories from Carbohydrate', '% Calories from Protein', 'Polyunsaturated to Saturated Fat Ratio',\n",
    "                 'Lutein + Zeaxanthin (mcg)', 'Choline (mg)']]\n",
    "    for val in updated_df[\"Participant ID\"]:\n",
    "        _id = val.split(\"_\")[0]\n",
    "        #print(_id)\n",
    "        updated_df.replace(val, _id, inplace=True)\n",
    "\n",
    "    #print(updated_df.head())\n",
    "    mom_df_list.append(updated_df)\n",
    "    #print(updated_df.shape)\n",
    "\n",
    "\n",
    "print(\"List of dataframes made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_list)\n",
    "concat_df = pd.concat(mom_df_list, ignore_index=True)\n",
    "concat_df = concat_df.sort_values(by=\"Participant ID\")\n",
    "#print(final_df.head())\n",
    "#print(final_df.tail())\n",
    "#print(final_df.shape)\n",
    "concat_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umn_df = concat_df[concat_df['Site ID'] == \"UMN\"]\n",
    "umn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_df = concat_df[concat_df['Site ID'] == \"UNC\"]\n",
    "unc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write mom concatenated file (all available data on a single spread sheet, with reduced columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_filename='Mom_concat_test1'\n",
    "csv_filename = \"{}.csv\".format(concat_filename)\n",
    "csv_filepath = os.path.join(data_dir_path, \"outputs\", csv_filename)\n",
    "xlsx_filename = \"{}.xlsx\".format(concat_filename)\n",
    "xlsx_filepath = os.path.join(data_dir_path, \"outputs\", xlsx_filename)\n",
    "\n",
    "\n",
    "#print( new_filepath)\n",
    "# write concatentation to file\n",
    "# write concatentation to file\n",
    "writer = pd.ExcelWriter(xlsx_filepath, engine='xlsxwriter')\n",
    "concat_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "concat_df.to_csv(csv_filepath, index=False)\n",
    "print(\"Written concat file, \", concat_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_mean_df=concat_df.groupby(\"Participant ID\").mean()\n",
    "mom_mean_df=mom_mean_df.drop(columns=\"Visit Number\")\n",
    "mom_mean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write mom mean file (all available data on a single spread sheet from concatenated file with subjects averaged across visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_filename = \"Mom_mean_test1\"\n",
    "csv_filename = \"{}.csv\".format(mean_filename)\n",
    "mean_filepath = os.path.join(data_dir_path, \"outputs\", csv_filename)\n",
    "xlsx_filename = \"{}.xlsx\".format(mean_filename)\n",
    "xlsx_filepath = os.path.join(data_dir_path, \"outputs\", xlsx_filename)\n",
    "\n",
    "writer = pd.ExcelWriter(xlsx_filepath, engine='xlsxwriter')\n",
    "concat_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "#print( new_filepath)\n",
    "# write concatentation to file\n",
    "mom_mean_df.to_csv(mean_filepath)\n",
    "print(\"Written mean file, \", mean_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_mean_df['Total Grams'].plot(kind='hist', colormap=\"spring\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_mean_df.plot(kind=\"scatter\", x=\"Copper (mg)\", y='Animal Protein (g)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Site Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_mean_site_df=concat_df.groupby(\"Site ID\").mean()\n",
    "mom_mean_site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_df_T = mom_mean_site_df.T\n",
    "mom_df_T.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_df_T.plot(kind=\"scatter\", x=\"UMN\", y='UNC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing more...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_df_mom = mom_mean_df[['Total Grams']]\n",
    "grams_df_child = child_mean_df[[\"Total Grams\"]]\n",
    "\n",
    "grams_df_child.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at text file 09\n",
    "\n",
    "\n",
    "child09_text_files = glob.glob(os.path.join(data_dir_path, \"*Child*09*\"))\n",
    "mom09_text_files = glob.glob(os.path.join(data_dir_path, \"*Mom*09*\"))\n",
    "\n",
    "print(\"Text Files Found:  \\nFor Mom: {} \\nFor Child: {}\".format(','.join(child09_text_files), ','.join(mom09_text_files)))\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather dataframes from individual files and concatenate into a large dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in child09_text_files:\n",
    "    child_df = pd.read_csv(file, encoding='latin1', sep='\\t')\n",
    "child_df.head()\n",
    "## concat multiple files together like above \n",
    "# .........."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list column names\n",
    "#for i in child_df.columns:\n",
    "#    print(i)\n",
    "# list categories of food from row 0 \n",
    "#for i in child_df.iloc[[0]]:\n",
    "#    print(child_df.loc[0, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in mom09_text_files:\n",
    "    mom_df = pd.read_csv(file, encoding='latin1', sep='\\t')\n",
    "mom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
